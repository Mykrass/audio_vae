{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Dense, Input\n",
    "from keras.layers import Conv2D, Flatten, Lambda\n",
    "from keras.layers import Reshape, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (129, 48, 1)\n",
    "intermediate_dim = 512\n",
    "latent_dim = 40\n",
    "batch_size = 16\n",
    "kernel_size = 6\n",
    "stride_size = 3\n",
    "filters = 16\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick by sampling fr an isotropic unit Gaussian.\n",
    "    # Arguments\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "    # Returns\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean=0 and std=1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "# VAE model = encoder + decoder\n",
    "# build encoder model\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "x = inputs\n",
    "for i in range(2):\n",
    "    filters *= 2\n",
    "    x = Conv2D(filters=filters,\n",
    "               kernel_size=kernel_size,\n",
    "               activation='tanh',\n",
    "               strides=stride_size,\n",
    "               padding='valid')(x)\n",
    "\n",
    "# shape info needed to build decoder model\n",
    "shape = K.int_shape(x)\n",
    "\n",
    "# generate latent vector Q(z|X)\n",
    "x = Flatten()(x)\n",
    "x = Dense(intermediate_dim, activation='tanh')(x)\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "# use reparameterization trick to push the sampling out as input\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "# instantiate encoder model\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "#encoder.summary()\n",
    "plot_model(encoder, to_file='../data/vae_cnn_encoder.png', show_shapes=True)\n",
    "\n",
    "# build decoder model\n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = Dense(shape[1] * shape[2] * shape[3], activation='tanh')(latent_inputs)\n",
    "x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
    "\n",
    "for i in range(2):\n",
    "    x = Conv2DTranspose(filters=filters,\n",
    "                        kernel_size=kernel_size,\n",
    "                        activation='tanh',\n",
    "                        strides=stride_size,\n",
    "                        padding='valid')(x)\n",
    "    filters //= 2\n",
    "\n",
    "outputs = Conv2DTranspose(filters=1,\n",
    "                          kernel_size=kernel_size,\n",
    "                          activation='sigmoid',\n",
    "                          padding='same',\n",
    "                          name='decoder_output')(x)\n",
    "\n",
    "# instantiate decoder model\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "#decoder.summary()\n",
    "plot_model(decoder, to_file='../data/vae_cnn_decoder.png', show_shapes=True)\n",
    "\n",
    "# instantiate VAE model\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = Model(inputs, outputs, name='vae')\n",
    "\n",
    "reconstruction_loss = mse(K.flatten(inputs), K.flatten(outputs))\n",
    "\n",
    "reconstruction_loss *= input_shape[0] * input_shape[1]\n",
    "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -5e-4\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='rmsprop')\n",
    "plot_model(vae, to_file='../data/vae_cnn.png', show_shapes=True)\n",
    "#vae.summary()\n",
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "# Finding approximate mean and std of data\n",
    "x_train = []\n",
    "train_features_path = '/home/ds/DataScience/Datasets/LibriSpeech/VAELibriSpeech/train-clean-wav/'\n",
    "n_files = len(os.listdir(train_features_path))\n",
    "n_train = 0\n",
    "for filename in sorted(os.listdir(train_features_path)):\n",
    "    full_filename = os.path.join(train_features_path, filename)\n",
    "    print(full_filename)\n",
    "    data = np.load(full_filename)\n",
    "    n_train += data.shape[0]\n",
    "    x_train += [data[np.random.randint(data.shape[0], size=1)]]\n",
    "x_train = np.vstack(x_train)\n",
    "x_mean = np.mean(x_train)\n",
    "x_std = np.std(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_features_path = '/home/ds/DataScience/Datasets/LibriSpeech/VAELibriSpeech/test-clean-wav/'\n",
    "n_files = len(os.listdir(test_features_path))\n",
    "n_test = 0\n",
    "for filename in sorted(os.listdir(test_features_path)):\n",
    "    full_filename = os.path.join(test_features_path, filename)\n",
    "    print(full_filename)\n",
    "    data = np.load(full_filename)\n",
    "    n_test += data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(n_train, n_test) (1047736, 30548)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pickle.dump(x_mean, open('../data/x_mean.pkl', 'wb'))\n",
    "pickle.dump(x_std, open('../data/x_std.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = pickle.load(open('../data/x_mean.pkl', 'rb'))\n",
    "x_std = pickle.load(open('../data/x_std.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x_train = []\n",
    "train_features_path = '/home/ds/DataScience/Datasets/LibriSpeech/VAELibriSpeech/train-clean-wav/'\n",
    "n_files = len(os.listdir(train_features_path))\n",
    "for epoch in range(epochs):\n",
    "    print(epoch)\n",
    "    for filename in sorted(os.listdir(train_features_path)):\n",
    "        print(filename)\n",
    "        full_filename = os.path.join(train_features_path, filename)\n",
    "        data = np.load(full_filename)\n",
    "        x_train = (data - x_mean)/x_std\n",
    "        x_train = x_train.reshape(x_train.shape + (1,))\n",
    "        n_batches = int(data.shape[0] / batch_size)\n",
    "        for batch in np.array_split(x_train, [ind*batch_size for ind in range(1, n_batches+1)]):\n",
    "            if batch.shape != (batch_size, data.shape[1], data.shape[2], 1):\n",
    "                continue\n",
    "            batch_loss = vae.train_on_batch(batch, y=None)\n",
    "        print(batch_loss)\n",
    "    vae.save_weights('/home/ds/DataScience/Models/audio_vae/40_6_3/{}.h5'.format(epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "x_train = []\n",
    "train_features_path = '/home/ds/DataScience/Datasets/LibriSpeech/VAELibriSpeech/train-clean-wav/'\n",
    "n_files = len(os.listdir(train_features_path))\n",
    "for epoch in range(epochs):\n",
    "    print(epoch)\n",
    "    for filename in sorted(os.listdir(train_features_path)):\n",
    "        print(filename)\n",
    "        full_filename = os.path.join(train_features_path, filename)\n",
    "        data = np.load(full_filename)\n",
    "        data = data[np.random.randint(data.shape[0], size=batch_size), :, :]\n",
    "        x_train = (data - x_mean)/x_std\n",
    "        x_train = x_train.reshape(x_train.shape + (1,))\n",
    "        print(vae.train_on_batch(x_train, y=None))\n",
    "    vae.save_weights('/home/ds/DataScience/Models/audio_vae/10/vae_cnn_audio_{}.h5'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Audio VAE",
   "language": "python",
   "name": "audio_vae_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
